#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ“ å–®ä»»å‹™åˆ†é¡æ¨¡å‹ (actionId)ï¼šåƒ…é æ¸¬ actionId
---------------------------------------------------------------------
ğŸŒŸ ä¾†æºï¼š
- å¾ v2 å¤šä»»å‹™æ¨¡å‹é‡æ§‹è€Œä¾†ï¼Œå°ˆæ³¨æ–¼ actionId é æ¸¬ã€‚
- ä¿ç•™äº† v2 çš„æ»¯å¾Œç‰¹å¾µ (prev_1, prev_2, prev_3) å’Œ score_diff ç‰¹å¾µã€‚
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from sklearn.feature_selection import VarianceThreshold
from tqdm import tqdm
import sys

# =========================================================
# 1ï¸âƒ£ è³‡æ–™è®€å– (ç„¡è®Šå‹•)
# =========================================================
def load_data(train_path="train.csv", test_path="test.csv"):
    """è®€å–è¨“ç·´é›†å’Œæ¸¬è©¦é›†"""
    try:
        train = pd.read_csv(train_path)
        test = pd.read_csv(test_path)
        print(f"âœ… Train shape: {train.shape}")
        print(f"âœ… Test shape: {test.shape}")
        return train, test
    except FileNotFoundError:
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° {train_path} æˆ– {test_path}ã€‚è«‹ç¢ºä¿æª”æ¡ˆåœ¨æ­£ç¢ºçš„è·¯å¾‘ã€‚")
        sys.exit(1)

# =========================================================
# 2ï¸âƒ£ ç‰¹å¾µå·¥ç¨‹ (ç„¡è®Šå‹•)
# =========================================================
def create_features(df):
    """ç‚º train å’Œ test æ•¸æ“šé›†å»ºç«‹æ–°çš„åºåˆ—ç‰¹å¾µ (æ»¯å¾Œç‰¹å¾µ)"""
    df_new = df.copy()
    
    # ç¢ºä¿è³‡æ–™æŒ‰å›åˆå’Œæ‹æ•¸æ’åº
    df_new = df_new.sort_values(by=['rally_uid', 'strickNumber'])
    
    # 1. æ»¯å¾Œç‰¹å¾µ (Lag Features)
    lag_cols = ['actionId', 'pointId', 'spinId', 'strengthId', 'positionId']
    
    print(f"  > æ­£åœ¨å»ºç«‹ N-1, N-2, N-3 æ»¯å¾Œç‰¹å¾µ...")
    for col in lag_cols:
        for n in [1, 2, 3]:
            df_new[f'prev_{n}_{col}'] = df_new.groupby('rally_uid')[col].shift(n)

    # 2. æƒ…å¢ƒç‰¹å¾µ (Context Features) - åˆ†æ•¸
    df_new['score_diff'] = df_new['scoreSelf'] - df_new['scoreOther']

    # å¡«å…… shift() ç”¢ç”Ÿçš„ NaNs
    fill_cols = [col for col in df_new.columns if 'prev_' in col]
    df_new[fill_cols] = df_new[fill_cols].fillna(-1) 

    return df_new

# =========================================================
# 3ï¸âƒ£ é è™•ç† (ç°¡åŒ–ç‰ˆ)
# =========================================================
def preprocess(train_df, test_df):
    """
    1. ä¿®æ­£ actionId çš„ -1 é¡åˆ¥å•é¡Œ
    2. å–å¾—æ¸¬è©¦é›†æœ€å¾Œä¸€ç­†è³‡æ–™
    """
    # é æ¸¬æ™‚ï¼šä½¿ç”¨æ¯å€‹ rally_uid çš„ "æœ€å¾Œä¸€ç­†" è³‡æ–™
    test_last_shot = test_df.groupby('rally_uid').tail(1).copy()
    print(f"âœ… Test (last shots) shape: {test_last_shot.shape}")

    # ä¿®æ­£ -1 é¡åˆ¥ (åƒ…é‡å° actionId)
    original_max_label = None
    if (train_df["actionId"] == -1).any():
        max_label = train_df["actionId"].max()
        original_max_label = max_label + 1
        print(f"âš ï¸ actionId å«æœ‰ -1ï¼Œå°‡å…¶æ›¿æ›ç‚º {original_max_label}")
        train_df["actionId"] = train_df["actionId"].replace(-1, original_max_label)
    
    return train_df, test_last_shot, original_max_label

# =========================================================
# 4ï¸âƒ£ å»ºç«‹è¨“ç·´ä»»å‹™ (N -> N+1) (ç°¡åŒ–ç‰ˆ)
# =========================================================
def create_training_data(train_df, feature_cols):
    """
    é‡æ–°å®šç¾©è¨“ç·´ä»»å‹™ (N -> N+1)
    - ç‰¹å¾µ (X) æ˜¯ç•¶å‰æ“Šçƒ (Shot N)
    - æ¨™ç±¤ (y) æ˜¯ "ä¸‹ä¸€çƒ" çš„ actionId (Shot N+1)
    """
    # ç‰¹å¾µ (X) æ˜¯ç•¶å‰æ“Šçƒ (Shot N)
    X = train_df[feature_cols].copy().fillna(0)

    # æ¨™ç±¤ (y) æ˜¯ "ä¸‹ä¸€çƒ" (Shot N+1) çš„ actionId
    y = train_df.groupby('rally_uid')['actionId'].shift(-1)
    
    # å„²å­˜ rally_uid ä»¥ä¾¿é€²è¡Œ group split
    rally_uids_for_split = train_df['rally_uid']

    # åˆªé™¤æ²’æœ‰ "ä¸‹ä¸€çƒ" çš„è¡Œ (å³æ¯å€‹å›åˆçš„æœ€å¾Œä¸€çƒ)
    valid_indices = y.notna()
    X = X[valid_indices]
    y = y[valid_indices]
    rally_uids_for_split = rally_uids_for_split[valid_indices]

    print(f"âœ… é‡æ–°å»ºç«‹è¨“ç·´é›† (N -> N+1)ï¼Œæ–° shape: {X.shape}")
    
    return X, y.astype(int), rally_uids_for_split

# =========================================================
# 5ï¸âƒ£ å»ºç«‹ç„¡æ´©æ¼çš„é©—è­‰é›† (Group Split) (ç°¡åŒ–ç‰ˆ)
# =========================================================
def create_group_split(X, y, rally_uids):
    """
    ä½¿ç”¨ Group Split å»ºç«‹ç„¡æ´©æ¼çš„é©—è­‰é›†
    """
    print("ğŸ§© å»ºç«‹ç„¡æ´©æ¼çš„é©—è­‰é›†ä¸­ (Group Split)...")
    unique_rallies = rally_uids.unique()
    train_rallies, valid_rallies = train_test_split(unique_rallies, test_size=0.2, random_state=42)

    train_mask = rally_uids.isin(train_rallies)
    valid_mask = rally_uids.isin(valid_rallies)

    X_train, X_valid = X[train_mask], X[valid_mask]
    y_train, y_valid = y[train_mask], y[valid_mask]
    
    return X_train, X_valid, y_train, y_valid

# =========================================================
# 6ï¸âƒ£ ç‰¹å¾µé¸å– (ç„¡è®Šå‹•çš„æ ¸å¿ƒå‡½å¼)
# =========================================================
def select_features(X, y, objective, num_class=None, top_k=30):
    """
    ä½¿ç”¨ XGBoost å…ˆè¨“ç·´ä¸€è¼ªï¼Œé¸å‡ºæœ€é‡è¦çš„å‰ K å€‹ç‰¹å¾µã€‚
    """
    selector = VarianceThreshold(threshold=0.0)
    X_var = selector.fit_transform(X)
    selected_cols = X.columns[selector.get_support()]
    
    X_var = pd.DataFrame(X_var, columns=selected_cols, index=X.index)

    model_params = {
        "objective": objective,
        "eval_metric": "mlogloss",
        "learning_rate": 0.1, "max_depth": 5, "n_estimators": 100,
        "subsample": 0.8, "colsample_bytree": 0.8,
        "random_state": 42, "tree_method": "hist",
        "num_class": num_class
    }

    model_tmp = xgb.XGBClassifier(**model_params)
    model_tmp.fit(X_var, y)

    importances = model_tmp.feature_importances_
    importance_df = pd.DataFrame({
        "feature": selected_cols,
        "importance": importances
    }).sort_values("importance", ascending=False)

    top_features = importance_df.head(top_k)["feature"].tolist()
    return top_features

# =========================================================
# 7ï¸âƒ£ XGBoost è¨“ç·´å‡½å¼ (ç„¡è®Šå‹•)
# =========================================================
def train_xgb(X_train, y_train, X_valid, y_valid, objective, num_class):
    """è¨“ç·´ XGBoost æ¨¡å‹çš„é€šç”¨å‡½å¼"""
    params = {
        "objective": objective,
        "eval_metric": "mlogloss",
        "learning_rate": 0.1,
        "max_depth": 7,
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "n_estimators": 200,
        "random_state": 42,
        "tree_method": "hist",
        "early_stopping_rounds": 30,
        "num_class": num_class
    }

    model = xgb.XGBClassifier(**params)
    model.fit(
        X_train,
        y_train,
        eval_set=[(X_valid, y_valid)],
        verbose=False
    )
    return model

# =========================================================
# 8ï¸âƒ£ æ¨™ç±¤é‚„åŸ (ç„¡è®Šå‹•çš„æ ¸å¿ƒå‡½å¼)
# =========================================================
def revert_negative(pred, replacement_val):
    """å°‡ max+1 é¡åˆ¥è½‰å› -1"""
    if replacement_val is not None:
        pred = pd.Series(pred)
        pred[pred == replacement_val] = -1
        return pred.values
    return pred

# =========================================================
# 9ï¸âƒ£ è¼¸å‡º submission.csv (ä¿®æ”¹ç‰ˆ)
# =========================================================
def save_submission(test_last_shot, pred_action, sample_path="sample_submission.csv", output_path="submission_actionId.csv"):
    """
    è®€å– sample_submissionï¼Œåƒ…æ›´æ–° actionId æ¬„ä½å¾Œå„²å­˜
    """
    try:
        submission = pd.read_csv(sample_path)
    except FileNotFoundError:
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° {sample_path}ã€‚ç„¡æ³•å»ºç«‹æäº¤æª”æ¡ˆã€‚")
        return
        
    # ç¢ºä¿ rally_uid å°é½Š
    submission = submission.set_index('rally_uid')
    
    # å»ºç«‹ä¸€å€‹åŒ…å«é æ¸¬çµæœçš„ Seriesï¼Œä¸¦ä»¥ rally_uid ç‚ºç´¢å¼•
    pred_df = pd.DataFrame({
        "rally_uid": test_last_shot["rally_uid"],
        "actionId": pred_action
    }).set_index('rally_uid')

    # æ›´æ–° actionId æ¬„ä½
    submission['actionId'].update(pred_df['actionId'])
    submission['actionId'] = submission['actionId'].astype(int)

    # æ¢å¾©ç´¢å¼•ä¸¦å„²å­˜
    submission.reset_index(inplace=True)
    submission.to_csv(output_path, index=False)
    print(f"\nâœ… å·²è¼¸å‡º {output_path}")
    print(f"Submission shape: {submission.shape}")
    print(submission.head())

# =========================================================
# ğŸš€ ä¸»åŸ·è¡Œæµç¨‹
# =========================================================
def main():
    # --- åƒæ•¸è¨­å®š ---
    K_FEATURES = 40
    TRAIN_PATH = "train.csv"
    TEST_PATH = "test.csv"
    SAMPLE_SUB_PATH = "sample_submission.csv"
    SUBMISSION_PATH = "submission_actionId.csv"

    # --- 1. è®€å–è³‡æ–™ ---
    train, test = load_data(TRAIN_PATH, TEST_PATH)

    # --- 2. ç‰¹å¾µå·¥ç¨‹ ---
    print("âš™ï¸ æ­£åœ¨ç‚º train å»ºç«‹æ»¯å¾Œç‰¹å¾µ...")
    train = create_features(train)
    print("âš™ï¸ æ­£åœ¨ç‚º test å»ºç«‹æ»¯å¾Œç‰¹å¾µ...")
    test = create_features(test)

    # --- 3. é è™•ç† ---
    target_cols = ["actionId", "pointId", "serverGetPoint"]
    drop_cols = ["rally_uid", "rally_id"] 
    feature_cols = [c for c in train.columns if c not in target_cols + drop_cols and c in test.columns]
    print(f"âœ… ä½¿ç”¨ {len(feature_cols)} å€‹ç‰¹å¾µé€²è¡Œè¨“ç·´ã€‚")
    
    train, test_last_shot, original_max_label = preprocess(train, test)

    # --- 4. å»ºç«‹ N -> N+1 è¨“ç·´è³‡æ–™ ---
    X, y, rally_uids_for_split = create_training_data(train, feature_cols)
    X_test = test_last_shot[feature_cols].copy().fillna(0)

    # --- 5. å»ºç«‹ Group Split ---
    X_train, X_valid, y_train, y_valid = create_group_split(X, y, rally_uids_for_split)
    
    num_class = y.nunique()

    # --- 6. ç‰¹å¾µé¸å– ---
    print(f"ğŸ§© ç‚º actionId é¸å–å‰ {K_FEATURES} å€‹ç‰¹å¾µ...")
    top_features = select_features(X_train, y_train, 
                                     objective="multi:softmax", 
                                     num_class=num_class, 
                                     top_k=K_FEATURES)
    print(f"ğŸ”¥ actionId Top 5: {top_features[:5]}")
    
    X_train_fs = X_train[top_features]
    X_valid_fs = X_valid[top_features]
    X_test_fs = X_test[top_features]

    # --- 7. è¨“ç·´æ¨¡å‹ ---
    print("\nğŸš€ è¨“ç·´ actionId æ¨¡å‹ä¸­...")
    model = train_xgb(X_train_fs, y_train, X_valid_fs, y_valid,
                      objective="multi:softmax", num_class=num_class)

    # --- 8. è©•ä¼°æ¨¡å‹ ---
    print("\nğŸ“Š Validation Results:")
    pred_valid = model.predict(X_valid_fs)
    f1_action = f1_score(y_valid, pred_valid, average="macro")
    print(f"actionId Macro F1: {f1_action:.4f}")

    # --- 9. ç”¢ç”Ÿé æ¸¬ ---
    print("\nğŸ§® ç”¢ç”Ÿæ¸¬è©¦é æ¸¬ä¸­...")
    pred_test = model.predict(X_test_fs)
    pred_test_reverted = revert_negative(pred_test, original_max_label)
    
    # --- 10. å„²å­˜æäº¤æª”æ¡ˆ ---
    save_submission(test_last_shot, pred_test_reverted, SAMPLE_SUB_PATH, SUBMISSION_PATH)

if __name__ == "__main__":
    main()